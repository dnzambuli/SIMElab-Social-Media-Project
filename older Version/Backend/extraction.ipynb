{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ghafla news \n",
    "\n",
    "using the link for (ghafla news)[https://www.ghafla.com/ke/]\n",
    "\n",
    "## The social listening\n",
    "\n",
    "1. allow the user to pass the information they need.\n",
    "2. provide an output file that is callable to the frontend\n",
    "\n",
    "## reason for json\n",
    "\n",
    "`Javascript` needs either a json file or a `mongoDB` connection. \n",
    "\n",
    "Json allows for integration and easy clearing of memory by just deleting the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghafla_data(name):\n",
    "    # Visit the website\n",
    "    url = \"https://www.ghafla.com/ke/\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Prompt user for input\n",
    "    search_term = name\n",
    "\n",
    "    # Fill the search input field\n",
    "    search_input = soup.find(\"input\", {\"name\": \"s\"})\n",
    "    search_input[\"value\"] = search_term\n",
    "\n",
    "    # Click the search button\n",
    "    search_button = soup.find(\"button\", {\"class\": \"btn btn-outline-secondary\"})\n",
    "    response = requests.get(url, params={\"s\": search_term})\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all search results\n",
    "    search_results = soup.find_all(\"div\", {\"class\": \"gfl-grid-item\"})\n",
    "\n",
    "    # Extract elements and store in a list of dictionaries\n",
    "    results_list = []\n",
    "    for result in search_results:\n",
    "        title = result.find(\"h5\").text.strip()\n",
    "        description = result.find(\"p\").text.strip()\n",
    "        link = result.find(\"a\")[\"href\"]\n",
    "        results_list.append({\"title\": title, \"description\": description, \"link\": link})\n",
    "\n",
    "    # Append the results to a JSON file\n",
    "    output_file = str(search_term) + \"_results.json\"\n",
    "    with open(output_file, \"a\") as f:\n",
    "        json.dump(results_list, f, indent=4)\n",
    "\n",
    "    print(\"Search results have been saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pulse News \n",
    "\n",
    "using the link to [pulse news](https://www.pulselive.co.ke/)\n",
    "\n",
    "## elements \n",
    "\n",
    "1. `input` the search field\n",
    "2. the key elements have a layout as follows. This sample used `elodie` as a topic.\n",
    "```html\n",
    "<div class=\"link\">\n",
    "    <div class=\"gradient-overlay\">\n",
    "        <a href=\"https://www.pulselive.co.ke/entertainment/video-of-elodie-zone-opening-up-on-challenges-in-her-life-stirs-social-media/sg84kqr\" title=\"Video of Elodie Zone opening up on challenges in her life stirs social media\"></a>\n",
    "    </div>\n",
    "                                \n",
    "    <picture style=\"--noscript-src: url(https://ocdn.eu/pulscms-transforms/1/irJktkpTURBXy8wZmQ0ZjM1NWUwMDIxNDkwYTI1ZGRmZWMwZTY2YjMwOC5qcGeSlQMAzN7NBDjNAl-TBcx4zEM); \" class=\"image-wrapper\"><source data-original=\"https://ocdn.eu/pulscms-transforms/1/B5hk9kpTURBXy8wZmQ0ZjM1NWUwMDIxNDkwYTI1ZGRmZWMwZTY2YjMwOC5qcGeSlQMAzN7NBDjNAl-TBcx4zEPeAAKhMAahMQA\" srcset=\"https://ocdn.eu/pulscms-transforms/1/B5hk9kpTURBXy8wZmQ0ZjM1NWUwMDIxNDkwYTI1ZGRmZWMwZTY2YjMwOC5qcGeSlQMAzN7NBDjNAl-TBcx4zEPeAAKhMAahMQA\" type=\"image/avif\"><source data-original=\"https://ocdn.eu/pulscms-transforms/1/Z4zk9kpTURBXy8wZmQ0ZjM1NWUwMDIxNDkwYTI1ZGRmZWMwZTY2YjMwOC5qcGeSlQMAzN7NBDjNAl-TBcx4zEPeAAKhMAWhMQA\" srcset=\"https://ocdn.eu/pulscms-transforms/1/Z4zk9kpTURBXy8wZmQ0ZjM1NWUwMDIxNDkwYTI1ZGRmZWMwZTY2YjMwOC5qcGeSlQMAzN7NBDjNAl-TBcx4zEPeAAKhMAWhMQA\" type=\"image/webp\"><img width=\"120\" height=\"67\" alt=\"YouTuber Elodie Zone\" title=\"YouTuber Elodie Zone\" class=\"image lazyloaded imageWrapper\" src=\"data:image/svg+xml;charset=utf8,%3Csvg%20xmlns%3D'http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg'%20width%3D'120'%20height%3D'67'%20data-ring-placeholder%3D'1'%3E%3C%2Fsvg%3E\" data-original=\"https://ocdn.eu/pulscms-transforms/1/irJktkpTURBXy8wZmQ0ZjM1NWUwMDIxNDkwYTI1ZGRmZWMwZTY2YjMwOC5qcGeSlQMAzN7NBDjNAl-TBcx4zEM\" fetchpriority=\"low\" decoding=\"async\" loading=\"lazy\"></picture> \n",
    "<h2>\n",
    "    \n",
    "    Video of Elodie Zone opening up on challenges in her life stirs social media\n",
    "</h2>\n",
    "<time class=\"date date-type-publicationDate\" datetime=\"2024-02-25T18:53:35.000+03:00\">February 25th 2024, 6:53:35 pm\n",
    "</time>\n",
    "\n",
    "                                \n",
    "</div>\n",
    "```\n",
    "\n",
    "## Things to note \n",
    "\n",
    "- pulse offers information on when a post was made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulse_data(name):\n",
    "    # Visit the website\n",
    "    url = \"https://www.pulselive.co.ke/search?q=\" + str(name)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all search results\n",
    "    search_results = soup.find_all(\"li\", {\"class\": \"generic-list-item\"})\n",
    "\n",
    "    # Extract elements and store in a list of dictionaries\n",
    "    results_list = []\n",
    "    for result in search_results:\n",
    "        title_tag = result.find(\"h2\")\n",
    "        title = title_tag.text.strip() if title_tag else \"No Title\"\n",
    "        link_tag = result.find(\"a\")\n",
    "        link = link_tag['href'] if link_tag else \"\"\n",
    "        time_tag = result.find(\"time\")\n",
    "        time_posted = time_tag['datetime'] if time_tag else \"Date N/a\"\n",
    "        results_list.append({\"title\": title, \"link\": link, \"time\": time_posted})\n",
    "\n",
    "    # Append the results to a JSON file\n",
    "    output_file = str(name) + \"_results.json\"\n",
    "    with open(output_file, \"a\") as f:\n",
    "        json.dump(results_list, f, indent=4)\n",
    "\n",
    "    print(\"Search results have been saved to\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiss News\n",
    "\n",
    "[kiss link](https://kiss100.co.ke/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kiss_data(name):\n",
    "    # Visit the website\n",
    "    url = \"https://kiss100.co.ke/search/?query=\" + str(name)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Find all search results\n",
    "    search_results = soup.find_all(\"div\", {\"class\": \"articles-result\"})\n",
    "    print(search_results)\n",
    "    # Extract elements and store in a list of dictionaries\n",
    "    results_list = []\n",
    "    for result in search_results:\n",
    "        title_tag = result.find(\"p\", {\"class\": \"title\"})\n",
    "        title = title_tag.text.strip() if title_tag else \"No title\"\n",
    "        desc_tag = result.find(\"p\")\n",
    "        description = desc_tag.text.strip() if desc_tag else \"No Description\"\n",
    "        img_tag = result.find('img')\n",
    "        image = img_tag['src'] if img_tag else \"No Image\"\n",
    "        link = result.find(\"a\")[\"href\"]\n",
    "        time_tag = result.find(\"span\", {\"class\": \"info readingTime\"})\n",
    "        time_posted = time_tag.text.strip() if time_tag else \"No Time\"\n",
    "        results_list.append({\"title\": title, \"description\": description, \"link\": link, \"time\": time_posted})\n",
    "\n",
    "    # Append the results to a JSON file\n",
    "    output_file = str(name) + \"_results.json\"\n",
    "    with open(output_file, \"a\") as f:\n",
    "        json.dump(results_list, f, indent=4)\n",
    "\n",
    "    print(\"Search results have been saved to\", output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform a Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job():\n",
    "    name = input(\"Enter a topic of interes: \")\n",
    "    kiss_data(name)\n",
    "    pulse_data(name)\n",
    "    ghafla_data(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Search results have been saved to Politics_results.json\n",
      "Search results have been saved to Politics_results.json\n",
      "Search results have been saved to Politics_results.json\n"
     ]
    }
   ],
   "source": [
    "job()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
